---
layout: post
title: "Windows Audio APIs"
---

A game needs audio and that is, based on my own experience, one of last aspects
aspiring gamedevs tend to work on. In fact this is the first time I play with
audio, at least at this low level.

For now I will focus on Windows, and the first thing I want to do is to see
which is the native way to play audio.

## Overwiew
Windows has had different Audio APIs over the years. The purpose of this post
is not to describe all of them but to focus on current solutions. So first of
all we will take a look at the [documentation][1] provided by Microsoft.

There are different APIs with different purposes, some of them work at a
lower-level and others at a higher-level, and it can be a bit confusing
as one might not know which is the right choice. Also the documentation
feels a bit sparse, like there are some bits of relevant information here
and there so it feels like I have to find the right pieces and fit them
together as if I was solving a puzzle.

Regarding audio, in the documentation I found 2 separate sections
[Audio and Video][3] and, the less intuitive, [Graphics and Gaming][4].
This later one refers to Direct X which includes several functionalities
which target game development, including playing sounds. Since I'm
making a game that's the one I probably want to use.

After taking a look at the mentioned sections, the relevant APIs seem to be:
- **Core Audio APIs**: introduced in Windows Vista and improved in Windows 7,
  which provides a low level audio access with lower latency, more reliability,
  etc.
- **DirectSound**: higher level API build on top of Core Audio. It seems to be
  part of Direct X but the [article][2] talking about it is from 2009. It is an
  old API which has been replaced.
- **XAudio2**: low-level API designed to improve the performance in games[^1]. It
  is the replacement for DirectSound.

## XAudio2
It seems clear that, from the mentioned APIs, XAudio2 is the one to use. So now
let's talk a bit about it.

### How is audio played?
To understand how to use XAudio2 API works we first have to understand the
different elemements involved, which are summarized in the following image.

![XAudio diagram]({% link devlog/images/xaudio_diagram.png %})

In order to play the audio, we have to send the audio data to the hardware. But
we won't do it directly. With the XAudio2 API this is done with _Voices_.
To play audio we send the data to a _Source Voice_ and, finally, a
_Mastering Voice_ sends the audio to the hardware.

The steps followed are something like:
1. Read the audio file (.wav, or .mp3, .flac or whatever supported format)
which contains the data of the audio to be played. In fact the file is
optional, we could generate the audio programmatically, or get it from a
stream, etc. But in the general case we will get the audio from a file.
2. Copy audio data to an internal _buffer_.
3. Send the _buffer_ to a _Source Voice_.
4. Finally the audio reaches a _Mastering Voice_, and from there is sent
   to the audio output hardware. 

#### Voices
Voices are the objects used in XAudio to process and play the audio data[^2].
There are 3 types:
- **Source Voices**: represent a stream of audio data. They are the first stage,
  where data buffers are submitted to.
- **Submix Voices**: manipulate the audio data they receive. They are an
  intermediate stage, and can be used to apply effects to the _Voice_ or
  _Voices_ at their input. For example, multiple _Source Voices_ could be
  sent to a _Submix Voice_, then use the _Submix Voice_ to control the
  volume of all those _Voices_.
- **Mastering Voices**: represent an audio output device. In order to hear it,
  the output of a _Source Voice_ or _Submit Voice_ must be send to a
  _Mastering Voice_.

Comparing it to an audio software, we can see a _Source Voice_
as an audio track, as we can have multiple tracks playing together at the same
time. Then a _Submix Voice_ can be seen as some layer used to apply effects
to a track or group of tracks. Finally a _Mastering Voice_ is the output mixer,
which sends the audio to the headphones or speakers so we can hear it.

## Conclusion
_Voices_ seem to be the main concept behind XAudio2 API and after this post we
have an overall understaing about how they work. In particular this helped me
to realize I initially misunderstood the concept of _Voices_ and now, after
a more careful reading of the documentation, I can give another try to the
XAudio2 API.

## References
[^1]: [https://learn.microsoft.com/en-us/windows/win32/xaudio2/xaudio2-apis-portal][5]
[^2]: [https://learn.microsoft.com/en-us/windows/win32/xaudio2/xaudio2-key-concepts][6]

[1]: https://learn.microsoft.com/en-us/windows/win32/coreaudio/about-the-windows-core-audio-apis
[2]: https://learn.microsoft.com/en-us/previous-versions/windows/desktop/bb318665(v=vs.85)
[3]: https://learn.microsoft.com/en-us/windows/win32/audio-and-video
[4]: https://learn.microsoft.com/en-us/windows/win32/directx
[5]: https://learn.microsoft.com/en-us/windows/win32/xaudio2/xaudio2-apis-portal
[6]: https://learn.microsoft.com/en-us/windows/win32/xaudio2/xaudio2-key-concepts
